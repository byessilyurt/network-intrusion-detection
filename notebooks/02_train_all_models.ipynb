{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Intrusion Detection - Master Training Notebook\n",
    "\n",
    "This notebook trains all 4 models:\n",
    "1. **Isolation Forest** - Fast classical baseline (~3s)\n",
    "2. **One-Class SVM** - High precision classical method (~1s)\n",
    "3. **Autoencoder** - Deep learning baseline (~40s)\n",
    "4. **VAE** - Advanced deep learning (~5-10 min)\n",
    "\n",
    "**Training Data:** Monday BENIGN (50K samples)\n",
    "\n",
    "**Test Data:** Wednesday DoS/DDoS (100K samples)\n",
    "\n",
    "**Features:**\n",
    "- ‚úÖ Automatic checkpointing (deep learning models)\n",
    "- ‚úÖ Early stopping\n",
    "- ‚úÖ Model persistence\n",
    "- ‚úÖ Comprehensive evaluation\n",
    "- ‚úÖ Visualizations\n",
    "\n",
    "**Estimated Runtime:** 15-20 minutes total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(str(Path.cwd().parent / 'src'))\n",
    "\n",
    "from data.preprocessing import CICIDS2017Preprocessor\n",
    "from models.isolation_forest import IsolationForestDetector\n",
    "from models.one_class_svm import OneClassSVMDetector\n",
    "from models.autoencoder import AutoencoderDetector\n",
    "from models.vae import VAEDetector\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úÖ Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "DATA_DIR = Path.cwd().parent / 'data' / 'raw'\n",
    "MODELS_DIR = Path.cwd().parent / 'models'\n",
    "CHECKPOINTS_DIR = Path.cwd().parent / 'checkpoints'\n",
    "RESULTS_DIR = Path.cwd().parent / 'results'\n",
    "\n",
    "# Create directories\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "CHECKPOINTS_DIR.mkdir(exist_ok=True)\n",
    "(CHECKPOINTS_DIR / 'autoencoder').mkdir(exist_ok=True)\n",
    "(CHECKPOINTS_DIR / 'vae').mkdir(exist_ok=True)\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Training config\n",
    "TRAIN_SAMPLES = 50000  # Monday BENIGN\n",
    "TEST_SAMPLES = 100000  # Wednesday DoS/DDoS\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(f\"üìÅ Data directory: {DATA_DIR}\")\n",
    "print(f\"üìÅ Models directory: {MODELS_DIR}\")\n",
    "print(f\"üìÅ Checkpoints directory: {CHECKPOINTS_DIR}\")\n",
    "print(f\"üìÅ Results directory: {RESULTS_DIR}\")\n",
    "print(f\"\\n‚úÖ Directories configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Monday BENIGN data (training)...\")\n",
    "df_monday = pd.read_csv(DATA_DIR / 'Monday-WorkingHours.pcap_ISCX.csv')\n",
    "print(f\"Monday data shape: {df_monday.shape}\")\n",
    "\n",
    "print(\"\\nLoading Wednesday DoS/DDoS data (testing)...\")\n",
    "df_wednesday = pd.read_csv(DATA_DIR / 'Wednesday-workingHours.pcap_ISCX.csv')\n",
    "print(f\"Wednesday data shape: {df_wednesday.shape}\")\n",
    "\n",
    "# Sample for faster training\n",
    "print(f\"\\nSampling {TRAIN_SAMPLES} training samples...\")\n",
    "df_train = df_monday.sample(n=min(TRAIN_SAMPLES, len(df_monday)), random_state=RANDOM_STATE)\n",
    "\n",
    "print(f\"Sampling {TEST_SAMPLES} test samples...\")\n",
    "df_test = df_wednesday.sample(n=min(TEST_SAMPLES, len(df_wednesday)), random_state=RANDOM_STATE)\n",
    "\n",
    "print(f\"\\n‚úÖ Data loaded\")\n",
    "print(f\"   Training samples: {len(df_train)}\")\n",
    "print(f\"   Test samples: {len(df_test)}\")\n",
    "print(f\"   Test attack distribution:\")\n",
    "print(df_test[' Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "print(\"Preprocessing data...\")\n",
    "preprocessor = CICIDS2017Preprocessor()\n",
    "\n",
    "# Fit on training data (BENIGN only)\n",
    "X_train, y_train = preprocessor.fit_transform(df_train)\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Training labels (should be all BENIGN=0): {np.unique(y_train, return_counts=True)}\")\n",
    "\n",
    "# Transform test data\n",
    "X_test, y_test = preprocessor.transform(df_test)\n",
    "print(f\"\\nTest data shape: {X_test.shape}\")\n",
    "print(f\"Test labels (0=BENIGN, 1=ATTACK): {np.unique(y_test, return_counts=True)}\")\n",
    "print(f\"Attack rate in test set: {y_test.mean():.1%}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Preprocessing complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    \"\"\"Evaluate model performance.\"\"\"\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{model_name} Results\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    \n",
    "    # Check quality gate\n",
    "    if f1 >= 0.85:\n",
    "        print(f\"‚úÖ QUALITY GATE PASSED (F1 >= 0.85)\")\n",
    "    else:\n",
    "        print(f\"‚ùå QUALITY GATE FAILED (F1 < 0.85, gap: {0.85-f1:.4f})\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    fp_rate = fp / (fp + tn)\n",
    "    \n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"  TN: {tn:,} | FP: {fp:,}\")\n",
    "    print(f\"  FN: {fn:,} | TP: {tp:,}\")\n",
    "    print(f\"\\nFalse Positive Rate: {fp_rate:.2%}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'fp_rate': fp_rate,\n",
    "        'tn': tn,\n",
    "        'fp': fp,\n",
    "        'fn': fn,\n",
    "        'tp': tp\n",
    "    }\n",
    "\n",
    "def save_results(results, filename):\n",
    "    \"\"\"Save results to pickle file.\"\"\"\n",
    "    with open(RESULTS_DIR / filename, 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "    print(f\"\\nüíæ Results saved to {filename}\")\n",
    "\n",
    "print(\"‚úÖ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING ISOLATION FOREST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train\n",
    "if_detector = IsolationForestDetector(\n",
    "    contamination=0.1,\n",
    "    n_estimators=100,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"Training Isolation Forest...\")\n",
    "if_detector.fit(X_train)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"‚úÖ Training complete in {training_time:.2f}s\")\n",
    "\n",
    "# Predict\n",
    "print(\"Predicting on test set...\")\n",
    "y_pred_if = if_detector.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "if_results = evaluate_model(y_test, y_pred_if, \"Isolation Forest\")\n",
    "if_results['training_time'] = training_time\n",
    "\n",
    "# Save model\n",
    "model_path = MODELS_DIR / 'isolation_forest_final.pkl'\n",
    "if_detector.save(model_path)\n",
    "print(f\"üíæ Model saved to {model_path}\")\n",
    "\n",
    "# Save results\n",
    "save_results(if_results, 'isolation_forest_results.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train One-Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING ONE-CLASS SVM\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train (subsample for speed)\n",
    "ocsvm_detector = OneClassSVMDetector(\n",
    "    kernel='rbf',\n",
    "    nu=0.01,\n",
    "    gamma='scale'\n",
    ")\n",
    "\n",
    "# Subsample training data for OCSVM (faster)\n",
    "X_train_ocsvm = X_train[:20000]\n",
    "print(f\"Training One-Class SVM on {len(X_train_ocsvm)} samples...\")\n",
    "ocsvm_detector.fit(X_train_ocsvm)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"‚úÖ Training complete in {training_time:.2f}s\")\n",
    "\n",
    "# Predict\n",
    "print(\"Predicting on test set...\")\n",
    "y_pred_ocsvm = ocsvm_detector.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "ocsvm_results = evaluate_model(y_test, y_pred_ocsvm, \"One-Class SVM\")\n",
    "ocsvm_results['training_time'] = training_time\n",
    "\n",
    "# Save model\n",
    "model_path = MODELS_DIR / 'ocsvm_final.pkl'\n",
    "ocsvm_detector.save(model_path)\n",
    "print(f\"üíæ Model saved to {model_path}\")\n",
    "\n",
    "# Save results\n",
    "save_results(ocsvm_results, 'ocsvm_results.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING AUTOENCODER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train\n",
    "ae_detector = AutoencoderDetector(\n",
    "    encoding_dims=[40, 20],\n",
    "    dropout_rate=0.2,\n",
    "    l2_reg=1e-5\n",
    ")\n",
    "\n",
    "print(\"Training Autoencoder...\")\n",
    "print(\"  - Checkpoints will be saved to checkpoints/autoencoder/\")\n",
    "print(\"  - Early stopping enabled (patience=10)\")\n",
    "print(\"  - This will take ~40 seconds...\\n\")\n",
    "\n",
    "# Train with checkpointing\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    str(CHECKPOINTS_DIR / 'autoencoder' / 'ae_checkpoint_epoch_{epoch:02d}.h5'),\n",
    "    save_freq='epoch',\n",
    "    period=5,  # Save every 5 epochs\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = ae_detector.fit(\n",
    "    X_train,\n",
    "    epochs=100,\n",
    "    batch_size=256,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[checkpoint_callback, early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"\\n‚úÖ Training complete in {training_time:.2f}s\")\n",
    "\n",
    "# Predict\n",
    "print(\"Predicting on test set...\")\n",
    "y_pred_ae = ae_detector.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "ae_results = evaluate_model(y_test, y_pred_ae, \"Autoencoder\")\n",
    "ae_results['training_time'] = training_time\n",
    "ae_results['history'] = history.history\n",
    "\n",
    "# Save model\n",
    "model_path = MODELS_DIR / 'autoencoder_final.h5'\n",
    "metadata_path = MODELS_DIR / 'autoencoder_final.pkl'\n",
    "ae_detector.save(model_path)\n",
    "print(f\"üíæ Model saved to {model_path}\")\n",
    "\n",
    "# Save results\n",
    "save_results(ae_results, 'autoencoder_results.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING VARIATIONAL AUTOENCODER (VAE)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train\n",
    "vae_detector = VAEDetector(\n",
    "    latent_dim=20,\n",
    "    encoder_dims=[50, 30],\n",
    "    kl_weight=0.001,\n",
    "    dropout_rate=0.2,\n",
    "    l2_reg=1e-5\n",
    ")\n",
    "\n",
    "print(\"Training VAE...\")\n",
    "print(\"  - Checkpoints will be saved to checkpoints/vae/\")\n",
    "print(\"  - Early stopping enabled (patience=10)\")\n",
    "print(\"  - This will take ~5-10 minutes...\\n\")\n",
    "\n",
    "# Train with checkpointing\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    str(CHECKPOINTS_DIR / 'vae' / 'vae_checkpoint_epoch_{epoch:02d}.h5'),\n",
    "    save_freq='epoch',\n",
    "    period=5,  # Save every 5 epochs\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = vae_detector.fit(\n",
    "    X_train,\n",
    "    epochs=100,\n",
    "    batch_size=256,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[checkpoint_callback, early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"\\n‚úÖ Training complete in {training_time:.2f}s ({training_time/60:.1f} minutes)\")\n",
    "\n",
    "# Predict\n",
    "print(\"Predicting on test set...\")\n",
    "y_pred_vae = vae_detector.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "vae_results = evaluate_model(y_test, y_pred_vae, \"VAE\")\n",
    "vae_results['training_time'] = training_time\n",
    "vae_results['history'] = history.history\n",
    "\n",
    "# Save model\n",
    "model_path = MODELS_DIR / 'vae_final.h5'\n",
    "metadata_path = MODELS_DIR / 'vae_final.pkl'\n",
    "vae_detector.save(model_path)\n",
    "print(f\"üíæ Model saved to {model_path}\")\n",
    "\n",
    "# Save results\n",
    "save_results(vae_results, 'vae_results.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all results\n",
    "all_results = pd.DataFrame([\n",
    "    if_results,\n",
    "    ocsvm_results,\n",
    "    ae_results,\n",
    "    vae_results\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(all_results[['model', 'f1', 'precision', 'recall', 'fp_rate', 'training_time']].to_string(index=False))\n",
    "\n",
    "# Find best model\n",
    "best_model = all_results.loc[all_results['f1'].idxmax()]\n",
    "print(f\"\\nüèÜ BEST MODEL: {best_model['model']} (F1={best_model['f1']:.4f})\")\n",
    "\n",
    "# Check quality gate\n",
    "if best_model['f1'] >= 0.85:\n",
    "    print(f\"‚úÖ QUALITY GATE PASSED - Ready for production!\")\n",
    "else:\n",
    "    gap = 0.85 - best_model['f1']\n",
    "    print(f\"‚ùå QUALITY GATE NOT MET - Need F1 improvement of {gap:.4f}\")\n",
    "    print(f\"\\nRecommendations:\")\n",
    "    print(f\"  - Try ensemble methods (combine OCSVM + VAE)\")\n",
    "    print(f\"  - Hyperparameter tuning\")\n",
    "    print(f\"  - Train on full dataset (530K samples vs current 50K)\")\n",
    "    print(f\"  - Feature engineering\")\n",
    "\n",
    "# Save final comparison\n",
    "all_results.to_csv(RESULTS_DIR / 'final_comparison.csv', index=False)\n",
    "print(f\"\\nüíæ Final comparison saved to results/final_comparison.csv\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# F1 scores\n",
    "axes[0].barh(all_results['model'], all_results['f1'])\n",
    "axes[0].axvline(0.85, color='red', linestyle='--', label='Quality Gate (0.85)')\n",
    "axes[0].set_xlabel('F1 Score')\n",
    "axes[0].set_title('Model Comparison - F1 Scores')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Precision vs Recall\n",
    "axes[1].scatter(all_results['recall'], all_results['precision'], s=200)\n",
    "for idx, row in all_results.iterrows():\n",
    "    axes[1].annotate(row['model'], (row['recall'], row['precision']), \n",
    "                    xytext=(5, 5), textcoords='offset points')\n",
    "axes[1].set_xlabel('Recall')\n",
    "axes[1].set_ylabel('Precision')\n",
    "axes[1].set_title('Precision vs Recall')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'final_comparison.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"üíæ Comparison plot saved to results/final_comparison.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "### 1. Review Results\n",
    "- Check the comparison table and plots above\n",
    "- Identify which model performed best\n",
    "- Check if quality gate (F1 > 0.85) was met\n",
    "\n",
    "### 2. Analyze Per-Attack Performance\n",
    "- Open `notebooks/03_model_comparison.ipynb`\n",
    "- Analyze per-attack-type detection rates\n",
    "- Identify which attacks are hardest to detect\n",
    "\n",
    "### 3. Report Back\n",
    "Come back with:\n",
    "- Best model name and F1 score\n",
    "- Whether quality gate was met\n",
    "- Any issues encountered during training\n",
    "\n",
    "### 4. Decide Next Phase\n",
    "**If F1 >= 0.85:**\n",
    "- Proceed to API development\n",
    "- Deploy to production\n",
    "\n",
    "**If F1 < 0.85:**\n",
    "- Try ensemble methods\n",
    "- Hyperparameter tuning\n",
    "- Train on full dataset\n",
    "- Feature engineering"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
