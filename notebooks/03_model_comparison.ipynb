{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison and Per-Attack Analysis\n",
    "\n",
    "This notebook provides detailed analysis of trained models:\n",
    "- Load saved models and results\n",
    "- Per-attack-type performance analysis\n",
    "- Confusion matrix visualizations\n",
    "- Training history plots (deep learning models)\n",
    "- Recommendations for next steps\n",
    "\n",
    "**Prerequisites:** Run `02_train_all_models.ipynb` first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(str(Path.cwd().parent / 'src'))\n",
    "\n",
    "from data.preprocessing import CICIDS2017Preprocessor\n",
    "from models.isolation_forest import IsolationForestDetector\n",
    "from models.one_class_svm import OneClassSVMDetector\n",
    "from models.autoencoder import AutoencoderDetector\n",
    "from models.vae import VAEDetector\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"âœ… Imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "DATA_DIR = Path.cwd().parent / 'data' / 'raw'\n",
    "MODELS_DIR = Path.cwd().parent / 'models'\n",
    "RESULTS_DIR = Path.cwd().parent / 'results'\n",
    "\n",
    "print(\"âœ… Directories configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all results\n",
    "with open(RESULTS_DIR / 'isolation_forest_results.pkl', 'rb') as f:\n",
    "    if_results = pickle.load(f)\n",
    "\n",
    "with open(RESULTS_DIR / 'ocsvm_results.pkl', 'rb') as f:\n",
    "    ocsvm_results = pickle.load(f)\n",
    "\n",
    "with open(RESULTS_DIR / 'autoencoder_results.pkl', 'rb') as f:\n",
    "    ae_results = pickle.load(f)\n",
    "\n",
    "with open(RESULTS_DIR / 'vae_results.pkl', 'rb') as f:\n",
    "    vae_results = pickle.load(f)\n",
    "\n",
    "all_results = pd.DataFrame([if_results, ocsvm_results, ae_results, vae_results])\n",
    "\n",
    "print(\"âœ… Results loaded\")\n",
    "print(\"\\nSummary:\")\n",
    "print(all_results[['model', 'f1', 'precision', 'recall', 'fp_rate', 'training_time']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Data for Per-Attack Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Wednesday test data...\")\n",
    "df_wednesday = pd.read_csv(DATA_DIR / 'Wednesday-workingHours.pcap_ISCX.csv')\n",
    "df_test = df_wednesday.sample(n=100000, random_state=42)\n",
    "\n",
    "# Preprocess\n",
    "preprocessor = CICIDS2017Preprocessor()\n",
    "# Load the fitted preprocessor from training\n",
    "X_test, y_test = preprocessor.fit_transform(df_test)  # Will need to load saved preprocessor in production\n",
    "\n",
    "# Get attack types\n",
    "attack_types = df_test[' Label'].values\n",
    "\n",
    "print(f\"âœ… Test data loaded: {len(df_test)} samples\")\n",
    "print(f\"\\nAttack distribution:\")\n",
    "print(df_test[' Label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models and Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "if_detector = IsolationForestDetector.load(MODELS_DIR / 'isolation_forest_final.pkl')\n",
    "ocsvm_detector = OneClassSVMDetector.load(MODELS_DIR / 'ocsvm_final.pkl')\n",
    "ae_detector = AutoencoderDetector.load(MODELS_DIR / 'autoencoder_final.h5')\n",
    "vae_detector = VAEDetector.load(MODELS_DIR / 'vae_final.h5')\n",
    "\n",
    "# Get predictions\n",
    "print(\"Getting predictions...\")\n",
    "y_pred_if = if_detector.predict(X_test)\n",
    "y_pred_ocsvm = ocsvm_detector.predict(X_test)\n",
    "y_pred_ae = ae_detector.predict(X_test)\n",
    "y_pred_vae = vae_detector.predict(X_test)\n",
    "\n",
    "print(\"âœ… Models loaded and predictions generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-Attack Type Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_attack_analysis(y_true, y_pred, attack_types, model_name):\n",
    "    \"\"\"Analyze performance per attack type.\"\"\"\n",
    "    df = pd.DataFrame({\n",
    "        'true': y_true,\n",
    "        'pred': y_pred,\n",
    "        'attack_type': attack_types\n",
    "    })\n",
    "    \n",
    "    results = []\n",
    "    for attack in df['attack_type'].unique():\n",
    "        mask = df['attack_type'] == attack\n",
    "        y_t = df.loc[mask, 'true'].values\n",
    "        y_p = df.loc[mask, 'pred'].values\n",
    "        \n",
    "        if attack == 'BENIGN':\n",
    "            # For benign, we want correct classification (0)\n",
    "            detection_rate = (y_p == 0).mean()\n",
    "        else:\n",
    "            # For attacks, we want detection (1)\n",
    "            detection_rate = (y_p == 1).mean()\n",
    "        \n",
    "        results.append({\n",
    "            'attack_type': attack,\n",
    "            'count': mask.sum(),\n",
    "            'detection_rate': detection_rate,\n",
    "            'model': model_name\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results).sort_values('detection_rate', ascending=False)\n",
    "\n",
    "# Analyze each model\n",
    "if_per_attack = per_attack_analysis(y_test, y_pred_if, attack_types, 'Isolation Forest')\n",
    "ocsvm_per_attack = per_attack_analysis(y_test, y_pred_ocsvm, attack_types, 'One-Class SVM')\n",
    "ae_per_attack = per_attack_analysis(y_test, y_pred_ae, attack_types, 'Autoencoder')\n",
    "vae_per_attack = per_attack_analysis(y_test, y_pred_vae, attack_types, 'VAE')\n",
    "\n",
    "# Combine all\n",
    "all_per_attack = pd.concat([if_per_attack, ocsvm_per_attack, ae_per_attack, vae_per_attack])\n",
    "\n",
    "print(\"Per-Attack Type Detection Rates:\\n\")\n",
    "print(all_per_attack.to_string(index=False))\n",
    "\n",
    "# Save\n",
    "all_per_attack.to_csv(RESULTS_DIR / 'per_attack_analysis.csv', index=False)\n",
    "print(f\"\\nðŸ’¾ Per-attack analysis saved to results/per_attack_analysis.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Per-Attack Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pivot table for heatmap\n",
    "pivot = all_per_attack.pivot(index='attack_type', columns='model', values='detection_rate')\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(pivot, annot=True, fmt='.2%', cmap='RdYlGn', vmin=0, vmax=1, cbar_kws={'label': 'Detection Rate'})\n",
    "plt.title('Per-Attack Type Detection Rates Heatmap', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Attack Type')\n",
    "plt.xlabel('Model')\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'per_attack_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"ðŸ’¾ Heatmap saved to results/per_attack_heatmap.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "models = [\n",
    "    ('Isolation Forest', y_pred_if),\n",
    "    ('One-Class SVM', y_pred_ocsvm),\n",
    "    ('Autoencoder', y_pred_ae),\n",
    "    ('VAE', y_pred_vae)\n",
    "]\n",
    "\n",
    "for idx, (name, y_pred) in enumerate(models):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "                xticklabels=['BENIGN', 'ATTACK'],\n",
    "                yticklabels=['BENIGN', 'ATTACK'])\n",
    "    ax.set_title(f'{name}\\nF1={all_results[all_results[\"model\"]==name][\"f1\"].values[0]:.4f}', \n",
    "                fontweight='bold')\n",
    "    ax.set_ylabel('True Label')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'all_confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"ðŸ’¾ Confusion matrices saved to results/all_confusion_matrices.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training History (Deep Learning Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Autoencoder\n",
    "ae_history = ae_results['history']\n",
    "axes[0].plot(ae_history['loss'], label='Training Loss')\n",
    "axes[0].plot(ae_history['val_loss'], label='Validation Loss')\n",
    "axes[0].set_title('Autoencoder Training History', fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# VAE\n",
    "vae_history = vae_results['history']\n",
    "axes[1].plot(vae_history['loss'], label='Training Loss')\n",
    "axes[1].plot(vae_history['val_loss'], label='Validation Loss')\n",
    "axes[1].set_title('VAE Training History', fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"ðŸ’¾ Training history saved to results/training_history.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = all_results.loc[all_results['f1'].idxmax()]\n",
    "worst_model = all_results.loc[all_results['f1'].idxmin()]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"KEY INSIGHTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nðŸ† Best Model: {best_model['model']}\")\n",
    "print(f\"   F1 Score: {best_model['f1']:.4f}\")\n",
    "print(f\"   Precision: {best_model['precision']:.4f}\")\n",
    "print(f\"   Recall: {best_model['recall']:.4f}\")\n",
    "print(f\"   False Positive Rate: {best_model['fp_rate']:.2%}\")\n",
    "print(f\"   Training Time: {best_model['training_time']:.2f}s\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Worst Model: {worst_model['model']}\")\n",
    "print(f\"   F1 Score: {worst_model['f1']:.4f}\")\n",
    "\n",
    "# Quality gate\n",
    "print(f\"\\nðŸŽ¯ Quality Gate (F1 >= 0.85):\")\n",
    "if best_model['f1'] >= 0.85:\n",
    "    print(f\"   âœ… PASSED - Ready for production!\")\n",
    "else:\n",
    "    gap = 0.85 - best_model['f1']\n",
    "    print(f\"   âŒ NOT MET - Need improvement of {gap:.4f}\")\n",
    "\n",
    "# Hardest attacks to detect\n",
    "attack_avg = all_per_attack[all_per_attack['attack_type'] != 'BENIGN'].groupby('attack_type')['detection_rate'].mean()\n",
    "hardest_attacks = attack_avg.nsmallest(3)\n",
    "\n",
    "print(f\"\\nâš ï¸  Hardest Attacks to Detect:\")\n",
    "for attack, rate in hardest_attacks.items():\n",
    "    print(f\"   - {attack}: {rate:.2%} average detection\")\n",
    "\n",
    "# Recommendations\n",
    "print(f\"\\nðŸ’¡ RECOMMENDATIONS:\")\n",
    "if best_model['f1'] >= 0.85:\n",
    "    print(f\"   1. Deploy {best_model['model']} to production\")\n",
    "    print(f\"   2. Monitor false positive rate ({best_model['fp_rate']:.2%})\")\n",
    "    print(f\"   3. Set up alerting pipeline\")\n",
    "    print(f\"   4. Build REST API for real-time detection\")\n",
    "else:\n",
    "    print(f\"   1. Try ensemble: Combine OCSVM (precision) + VAE (recall)\")\n",
    "    print(f\"   2. Hyperparameter tuning: Grid search on VAE latent_dim and kl_weight\")\n",
    "    print(f\"   3. Train on full dataset: 530K samples vs current 50K\")\n",
    "    print(f\"   4. Feature engineering: Add temporal/statistical aggregations\")\n",
    "    print(f\"   5. Test on other attack types: Tuesday (Brute Force), Thursday (Web), Friday (PortScan)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary report\n",
    "report = f\"\"\"\n",
    "NETWORK INTRUSION DETECTION - TRAINING SUMMARY REPORT\n",
    "====================================================\n",
    "\n",
    "Training Date: {pd.Timestamp.now()}\n",
    "Training Data: Monday BENIGN (50,000 samples)\n",
    "Test Data: Wednesday DoS/DDoS (100,000 samples)\n",
    "\n",
    "MODEL PERFORMANCE\n",
    "-----------------\n",
    "{all_results[['model', 'f1', 'precision', 'recall', 'fp_rate', 'training_time']].to_string(index=False)}\n",
    "\n",
    "BEST MODEL: {best_model['model']}\n",
    "  F1 Score: {best_model['f1']:.4f}\n",
    "  Precision: {best_model['precision']:.4f}\n",
    "  Recall: {best_model['recall']:.4f}\n",
    "  FP Rate: {best_model['fp_rate']:.2%}\n",
    "  Training Time: {best_model['training_time']:.2f}s\n",
    "\n",
    "QUALITY GATE (F1 >= 0.85): {'PASSED âœ…' if best_model['f1'] >= 0.85 else f\"NOT MET âŒ (gap: {0.85-best_model['f1']:.4f})\"}\n",
    "\n",
    "HARDEST ATTACKS TO DETECT\n",
    "-------------------------\n",
    "{chr(10).join([f\"  - {attack}: {rate:.2%}\" for attack, rate in hardest_attacks.items()])}\n",
    "\n",
    "FILES GENERATED\n",
    "---------------\n",
    "  - models/isolation_forest_final.pkl\n",
    "  - models/ocsvm_final.pkl\n",
    "  - models/autoencoder_final.h5\n",
    "  - models/vae_final.h5\n",
    "  - results/final_comparison.csv\n",
    "  - results/per_attack_analysis.csv\n",
    "  - results/per_attack_heatmap.png\n",
    "  - results/all_confusion_matrices.png\n",
    "  - results/training_history.png\n",
    "\n",
    "NEXT STEPS\n",
    "----------\n",
    "\"\"\" + (f\"\"\"\n",
    "  1. Deploy {best_model['model']} to production\n",
    "  2. Build REST API for real-time detection\n",
    "  3. Set up monitoring and alerting\n",
    "\"\"\" if best_model['f1'] >= 0.85 else f\"\"\"\n",
    "  1. Try ensemble methods\n",
    "  2. Hyperparameter tuning\n",
    "  3. Train on full dataset (530K samples)\n",
    "  4. Feature engineering\n",
    "\"\"\")\n",
    "\n",
    "# Save report\n",
    "with open(RESULTS_DIR / 'TRAINING_SUMMARY.txt', 'w') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(report)\n",
    "print(f\"\\nðŸ’¾ Summary report saved to results/TRAINING_SUMMARY.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
